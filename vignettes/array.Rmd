---
title: "Array"
author: "Lambda Moses"
date: "5/20/2020"
output: html_document
params:
  sheet: "Array"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Here I explore the history and geography of spatial transcriptomics based on microdissection through the metadata I collected.
```{r}
library(tidyverse)
library(googlesheets4)
library(lubridate)
library(magick)
library(scales)
library(zeallot)
source("code/metadata_plotting.R")
theme_set(theme_bw())
```

# Import data
```{r}
gs4_deauth()
sheet <- read_sheet("https://docs.google.com/spreadsheets/d/1sJDb9B7AtYmfKv4-m8XR7uc3XXw_k4kGSout8cqZ8bY/edit#gid=566523154", sheet = params$sheet)
```

Add the year column as this will be used for plotting rather than the full date.
```{r}
sheet <- sheet %>% 
  mutate(year = year(date_published))
```

# Number of publications
How many publications per year?
```{r}
# Remove duplicates as different datasets in the same publication have their own rows
publications <- sheet %>% 
  select(year, title, journal, accession, repo:department) %>% 
  distinct()
```

```{r}
anyDuplicated(publications$title)
```

How many publications are there in total in this sheet?
```{r}
nrow(publications)
```

```{r}
# For maps later in this notebook
c(inst_gc, city_gc) %<-% geocode_inst_city(publications)
pubs_on_map2 <- partial(pubs_on_map, inst_gc = inst_gc, city_gc = city_gc)
```

## Overall
Number of publications per year. Preprints are excluded from plots over years as it takes months to publish so the dates of the preprints are incoherent with those for the other papers. 
```{r}
gs4_deauth()
events <- read_sheet("https://docs.google.com/spreadsheets/d/1sJDb9B7AtYmfKv4-m8XR7uc3XXw_k4kGSout8cqZ8bY/edit#gid=566523154", sheet = "major events")
events$date_published <- as_date(events$date_published)
```

```{r, fig.width=5.5, fig.height=2}
events %>% 
  filter(category == "array") %>% 
  plot_timeline(rep(c(1, -1), length.out = nrow(.)), 
                expand_x = c(0.1, 0.1), expand_y = c(0.05, 0.05))
```

Is it bad to borrow the original figures from those historical papers? Well, here I sort of want to frame then as museum exhibits so it's all the cooler to have the original rather than my parody.

```{r}
pubs_per_year(publications,)
```

## By method
How about when broken down by method (not for data analysis sheets)?

```{r}
methods <- sheet %>% 
  select(year, title, journal, method, country, institution) %>% 
  distinct()
```

```{r, fig.width=4, fig.height=3}
pubs_per_year(methods, facet_by = method)
```
I don't know how much this actually says due to the small sample size. This is also kind of confusing since Geo-seq really is a form of LCM coupled with SMART-seq, so it should be categorized as LCM, but the authors gave it a new name. 

## By species
```{r}
species_img <- readRDS("output/species_img.rds")
```

```{r}
species <- sheet %>% 
  select(year, title, species, country, institution) %>% 
  distinct()
```

```{r}
unique(species$species)
```

```{r}
pubs_per_cat(species, category = "species")
```

```{r}
species_img$image <- purrr::map(species_img$image_paths, image_read)
```

```{r, fig.width=4, fig.height=2}
species %>% 
  left_join(species_img, by = "species") %>% 
  pubs_per_cat(category = "species", isotype = TRUE, img_unit = 1)
```

I debated for a while which image to use for humans. In order to avoid racist and sexist connotations, I picked the skull as non-experts can't tell the race and sex from the skull. If you think it's bad to use a skull, then I'll use a Black, Hispanic, Middle Eastern, North African, Central Asian, or South Asian woman's portrait. I stand with the oppressed.

## By journal
```{r}
sort(table(publications$journal))
```

## Location
### General
Just some barplots for number of publications per institution, city, and country. I think city is more informative than country, since obviously, for instance, San Francisco is very different from Anchorage, though they are both in the US. Just within the US, there are regions that are very innovative, and regions that are more repressive. Well, even LA has very different neighborhoods... I just think it's not fair to judge people by whether there's a strong country behind them. First of all, different regions within a countries are not the same. Second, it's not fair to consider someone dumb just because their country is poor and weak; all else being equal, I would admire the person from the poor country more since they had to work harder to get here. I don't care which country is behind you. Right is right, wrong is wrong. Anyway, this is not the place to ramble about politics.
```{r}
pubs_per_cat(publications, "country")
```

How about per capita? Actually this probably does not say much since many researchers in the West are immigrants. Then it raises the burning political question of who counts as the "population".

```{r}
pubs_per_capita(publications, plot = "bar")
```

Why is Israel doing so great? Why not freedom to Palestine? Yeah, freedom to Palestine!

How about country over time? There might not be enough publications to show a trend.
```{r}
pubs_per_year(publications, facet_by = "country")
```
Now look at cities. 

```{r}
pubs_per_cat(publications, "city")
```

Institutions
```{r}
pubs_per_cat(publications, "institution")
```

OK, now here comes the maps!

### Worldwide
```{r}
pubs_on_map2(publications)
```

Let me also plot the per capita thing on a map, as a choropleth
```{r}
pubs_per_capita(publications)
```

Break down by species
```{r, fig.width=5, fig.height=2}
pubs_on_map2(species, facet_by = "species")
```

By method
```{r, fig.width=5, fig.height=2}
pubs_on_map2(methods, facet_by = "method")
```

It seems that ST is the only method that did spread

### Europe
Plot a map just for Europe. A problem here is that if I simply filter the `world` sf object, I'll get some islands away from what we usually think is Europe. Kind of feel bad for Russians since Russia is so large that it makes the map look bad and I don't have a paper from Russia in this spreadsheet. 

```{r}
pubs_on_map2(publications, zoom = "europe")
```

```{r}
pubs_per_capita(publications, "europe")
```

I didn't realize that Switzerland and Netherlands were pretty great. Again, this is a small sample size, so I take this with a grain of salt until I plot the other sheets. From the other sheets, I already know that Sweden, the UK, and Germany have many contributions. 

```{r}
pubs_on_map2(species, zoom = "europe", facet_by = "species")
```

Maybe I just made this plot for fun. Not sure what to say about it.

```{r}
pubs_on_map2(methods, zoom = "europe", facet_by = "method")
```

So all the other methods are American

### USA
Also a plot just for America. I did not encounter a publication in this spreadsheet that is from Hawaii or Alaska, but I'll include Hawaii and Alaska in the map anyway in case I get one in the future.

```{r}
pubs_on_map2(publications, zoom = "usa")
```

```{r}
pubs_per_capita(publications, "usa")
```

```{r}
pubs_on_map2(species, zoom = "usa", facet_by = "species")
```

```{r}
pubs_on_map2(methods, zoom = "usa", facet_by = "method")
```

# Number of datasets
Since I did not always read the paper very carefully, take this with a grain of salt. Also, sometimes I'm not sure what counts as a dataset. The authors may test a technique on cell culture with just a few genes before moving on to real tissue, and I'm not sure if this should be included. But for microdissection, that's not an issue. Another thing I'm not sure about is biological and technical replica presented together on the paper. Should each replicate count as a dataset or should all the replica count as one dataset as they're intended to answer the same question and are analyzed together as they they were one?
```{r}
sheet %>% 
  count(title, method) %>% 
  ggplot(aes(n)) +
  geom_bar() +
  scale_y_continuous(expand = expansion(c(0, 0.05))) +
  scale_x_continuous(breaks = breaks_width(1))
```

# Word cloud
## Titles
```{r}
plot_wordcloud(sheet)
```

```{r}
plot_wordcloud(sheet, species_use = "Mus musculus")
```

```{r}
plot_wordcloud(sheet, species_use = "Homo sapiens")
```

## Tissues
```{r}
plot_wordcloud(sheet, col_use = "tissue")
```

```{r}
plot_wordcloud(sheet, species_use = "Mus musculus", col_use = "tissue")
```

```{r}
plot_wordcloud(sheet, species_use = "Homo sapiens", col_use = "tissue")
```

## Department names
```{r}
institution_words <- readRDS("output/inst_words.rds")
```

```{r}
plot_wordcloud(sheet, col_use = "department", other_stop_words = institution_words)
```

## Downstream analyses
```{r}
plot_wordcloud(sheet, "downstream")
```

# Programming languages
```{r}
langs <- sheet %>% 
  select(year, title, language) %>% 
  filter(!is.na(language)) %>% 
  distinct() %>% 
  mutate(language = str_split(language, "; ")) %>% 
  unnest(cols = "language")
```

```{r}
lang_img <- readRDS("output/lang_img.rds")
lang_img$image <- purrr::map(lang_img$image_paths, image_read)
```

```{r}
langs %>% 
  inner_join(lang_img, by = "language") %>% 
  pubs_per_cat(category = "language", isotype = TRUE, img_unit = 2)
```

# Data and code availability

How many publications have provided a code repo?
```{r}
ggplot(publications, aes(year, color = !is.na(repo))) +
  geom_freqpoly(binwidth = 1)
```

How many publications have provided an accession for sequencing data?
```{r}
ggplot(publications, aes(year, color = !is.na(accession))) +
  geom_freqpoly(binwidth = 1)
```

I don't think it's significant.
