---
title: "Analysis"
author: "Lambda Moses"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Here I explore the history and geography of spatial transcriptomics data analysis method through the metadata I collected.
```{r}
library(museumst)
library(purrr)
library(dplyr)
library(ggplot2)
library(sf)
theme_set(theme_bw())
```

# Import data
By default, the `read_metadata` function reads the appropriate sheet from a cache within this package. This may be outdated, since the Google Sheets are constantly updated. Use the argument `update = TRUE` to download the most up to date version. The default is `FALSE` to avoid API limits during automated CRAN checks.
```{r}
sheet <- read_metadata("Analysis")
```

# Number of publications
How many publications per year?

```{r}
anyDuplicated(sheet$title)
```

How many publications are there in total in this sheet?
```{r}
nrow(sheet)
```

```{r}
# For maps later in this notebook
city_gc <- geocode_inst_city(sheet)
pubs_on_map2 <- partial(pubs_on_map, city_gc = city_gc)
```

## Overall
By default, preprints are excluded from plots of number of publications over time, since the timing of preprints is incoherent to that of published papers. Including preprints will inflate the number of publications in recent months, and if we make the same plot a few months later, that inflation we see now will be gone and moved to a more recent date. You can add the `preprints = TRUE` argument to all functions plotting things over time in this package to include preprints. You can also use the `binwidth` argument to specify bin width in days. The default is 365 days.
```{r}
pubs_per_year(sheet)
```

## By category
By the category of problem to address
```{r}
category <- unnest_cat(sheet, category)
```

```{r}
pubs_per_cat(category, category)
```

```{r, fig.width=4, fig.height=4}
pubs_per_year(category, facet_by = "category", n_top = 5, sort_by = "recent_count")
```

```{r}
principle <- unnest_cat(sheet, core_principle)
```

```{r}
pubs_per_cat(principle, core_principle)
```

## By species
These are the species the computational methods were demonstrated on

```{r}
species <- unnest_cat(sheet, species)
```

```{r}
pubs_per_cat(species, species)
```

```{r}
pubs_per_cat(species, species, n_top = 5, isotype = TRUE, img_unit = 2)
```

I debated for a while which image to use for humans. In order to avoid racist and sexist connotations, I picked the skull as non-experts can't tell the race and sex from the skull. If you think it's bad to use a skull, then I'll use a Black, Hispanic, Middle Eastern, North African, Central Asian, or South Asian woman's portrait. I stand with the oppressed.

## By journal
```{r}
sort(table(sheet$journal))
```

## Location
### General
Just some barplots for number of publications per institution, city, and country. 
```{r}
pubs_per_cat(sheet, country)
```

How about per capita? Actually this probably does not say much since many researchers in the West are immigrants. Then it raises the burning political question of who counts as the "population".

```{r}
pubs_per_capita(sheet, plot = "bar")
```

How about country over time? 
```{r, fig.height=12, fig.width=6}
pubs_per_year(sheet, facet_by = "country")
```
Now look at cities. 

```{r}
pubs_per_cat(sheet, city)
```

Institutions
```{r}
pubs_per_cat(sheet, institution)
```

### Worldwide
```{r}
pubs_on_map2(sheet)
```

Let me also plot the per capita thing on a map, as a choropleth
```{r}
pubs_per_capita(sheet)
```

Break down by species
```{r, fig.width=8, fig.height=4}
pubs_on_map2(species, facet_by = "species")
```

### Europe
Plot a map just for Europe. A problem here is that if I simply filter the `world` sf object, I'll get some islands away from what we usually think is Europe. Kind of feel bad for Russians since Russia is so large that it makes the map look bad and I don't have a paper from Russia in this spreadsheet. 

```{r}
pubs_on_map(sheet, city_gc, zoom = "europe")
```

```{r}
pubs_per_capita(sheet, "europe")
```

I didn't realize that Switzerland and Netherlands were pretty great. Again, this is a small sample size, so I take this with a grain of salt.

```{r}
pubs_on_map2(species, zoom = "europe", facet_by = "species")
```

Maybe I just made this plot for fun. Not sure what to say about it.

### USA
Also a plot just for America. I did not encounter a publication in this spreadsheet that is from Hawaii or Alaska, but I'll include Hawaii and Alaska in the map anyway in case I get one in the future.

```{r}
pubs_on_map(sheet, zoom = "usa", city_gc = city_gc)
```

```{r}
pubs_per_capita(sheet, "usa")
```

```{r, fig.width=8, fig.height=3}
pubs_on_map2(species, zoom = "usa", facet_by = "species")
```

# Word cloud
## Titles
```{r, fig.height=7, fig.width=7}
plot_wordcloud(sheet)
```

## Summaries
```{r, fig.height=7, fig.width=7}
plot_wordcloud(sheet, summary)
```

```{r, fig.height=7, fig.width=7}
plot_wordcloud(sheet, core_principle, scale = c(5, 0.1))
```

## Tissues
```{r, fig.width=4, fig.height=4}
plot_wordcloud(sheet, tissue)
```

## Over time

```{r}
range(sheet$date_published)
```

```{r, fig.height=6, fig.width=6}
plot_wordcloud(sheet, year_min = 2009, year_max = 2015, scale = c(5, 0.1))
```

```{r, fig.height=7, fig.width=7}
plot_wordcloud(sheet, year_min = 2015, year_max = 2021)
```

## Department names

```{r, fig.height=7, fig.width=7}
plot_wordcloud(sheet, col_use = "department", other_stop_words = inst_words,
              scale = c(5, 0.1))
```

# Programming languages
```{r}
langs <- unnest_cat(sheet, language, c("documented", "packaged", "CRAN/Bioc/pip/conda"))
```

Here each icon stands for 2 publications.
```{r}
pubs_per_cat(langs, language, n_top = 5, isotype = TRUE, img_unit = 2)
```

Not sure of MathWorks will get mad at me for using their logo this way, since they don't want people to put their logo into a pattern and I'm not entirely sure if this counts as pattern.

# Data and code availability

How many publications have provided a code repo?
```{r}
hist_bool(sheet, !is.na(repo), preprints = TRUE)
```

It seems that more recent publications are more likely to provide a repo. Is this significant? 
```{r}
test_year_bool(sheet, !is.na(repo))
```

Yep, it's significant. How about whether the code is well-documented?

```{r, fig.width=6, fig.height=9}
pubs_per_year(langs, "language", binwidth = 150)
```

```{r}
hist_bool_line(langs, documented, facet_by = "language", preprints = TRUE, n_top = 5) 
```

It seems that R, Python, and C++ packages are more likely to be well-documented, and MATLAB ones are less likely. Is that MATLAB culture?
```{r}
hist_bool_line(langs, `CRAN/Bioc/pip/conda`, "language", preprints = TRUE, n_top = 5)
```

It seems that most packages are not on those public repos, not even R packages. Why? Too lazy to write documentations?
```{r}
langs %>% 
  filter(complete.cases(.)) %>% 
  glm(data = ., documented ~ `CRAN/Bioc/pip/conda`, family = "binomial") %>% 
  summary()
```

So it seems that packages on those public repos sort of tend to be better documented, though this is not really significant.

```{r}
sessionInfo()
```

