---
title: "Analysis"
author: "Lambda Moses"
date: "5/25/2020"
output: html_document
params:
  sheet: "Analysis"

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Here I explore the history and geography of spatial transcriptomics based on microdissection through the metadata I collected.
```{r}
library(tidyverse)
library(googlesheets4)
library(lubridate)
library(magick)
library(scales)
library(zeallot)
source("code/metadata_plotting.R")
theme_set(theme_bw())
```

# Import data
```{r}
gs4_deauth()
sheet <- read_sheet("https://docs.google.com/spreadsheets/d/1sJDb9B7AtYmfKv4-m8XR7uc3XXw_k4kGSout8cqZ8bY/edit#gid=566523154", sheet = params$sheet)
```

Add the year column as this will be used for plotting rather than the full date.
```{r}
sheet <- sheet %>% 
  mutate(year = year(date_published))
```

# Number of publications
How many publications per year?
```{r}
# Remove duplicates as different datasets in the same publication have their own rows
publications <- sheet %>% 
  select(year, title, journal, repo:department) %>% 
  distinct()
```

```{r}
anyDuplicated(publications$title)
```

How many publications are there in total in this sheet?
```{r}
nrow(publications)
```

```{r}
# For maps later in this notebook
c(inst_gc, city_gc) %<-% geocode_inst_city(publications)
pubs_on_map2 <- partial(pubs_on_map, inst_gc = inst_gc, city_gc = city_gc)
```

## Overall

```{r}
pubs_per_year(publications)
```

## By category
By the category of problem to address
```{r}
category <- sheet %>% 
  mutate(category = str_split(category, pattern = "(;|,)\\s")) %>% 
  select(year, title, journal, category, country, institution) %>% 
  unnest(cols = "category")
```

```{r}
pubs_per_cat(category, "category")
```

```{r, fig.width=4, fig.height=8}
pubs_per_year(category, facet_by = "category")
```
```{r}
principle <- sheet %>% 
  mutate(core_principle = str_split(core_principle, pattern = "(;|,)\\s")) %>% 
  select(year, title, journal, core_principle, country, institution) %>% 
  unnest(cols = "core_principle") %>% 
  filter(!is.na(core_principle))
```

```{r}
pubs_per_cat(principle, "core_principle")
```

## By species
These are the species the computational methods were demonstrated on
```{r}
species_img <- readRDS("output/species_img.rds")
```

```{r}
species <- sheet %>% 
  select(year, title, species, country, institution) %>% 
  filter(!is.na(species)) %>% 
  mutate(species = str_split(species, "; ")) %>% 
  unnest(cols = "species") %>%
  distinct()
```

```{r}
unique(species$species)
```

```{r}
pubs_per_cat(species, category = "species")
```

```{r}
top_species <- species %>% 
  count(species) %>%
  top_n(5, n) %>% 
  arrange(desc(n)) %>% 
  pull(species)
species_img$image <- purrr::map(species_img$image_paths, image_read)
```

```{r}
species %>% 
  filter(species %in% top_species) %>% 
  left_join(species_img, by = "species") %>% 
  pubs_per_cat(category = "species", isotype = TRUE, img_unit = 2)
```

I debated for a while which image to use for humans. In order to avoid racist and sexist connotations, I picked the skull as non-experts can't tell the race and sex from the skull. If you think it's bad to use a skull, then I'll use a Black, Hispanic, Middle Eastern, North African, Central Asian, or South Asian woman's portrait. I stand with the oppressed.

## By journal
```{r}
sort(table(publications$journal))
```

## Location
### General
Just some barplots for number of publications per institution, city, and country. 
```{r}
pubs_per_cat(publications, "country")
```

How about per capita? Actually this probably does not say much since many researchers in the West are immigrants. Then it raises the burning political question of who counts as the "population".

```{r}
pubs_per_capita(publications, plot = "bar")
```

How about country over time? There might not be enough publications to show a trend.
```{r, fig.height=8, fig.width=4}
pubs_per_year(publications, facet_by = "country")
```
Now look at cities. 

```{r}
pubs_per_cat(publications, "city")
```

Institutions
```{r}
pubs_per_cat(publications, "institution")
```

### Worldwide
```{r}
pubs_on_map2(publications)
```

Let me also plot the per capita thing on a map, as a choropleth
```{r}
pubs_per_capita(publications)
```

Break down by species
```{r, fig.width=5, fig.height=3}
pubs_on_map2(species, facet_by = "species")
```


Probably this does not tell us much since there's only 1 study for some species. Again, we see the received wisdom that research is mostly confined to the West, especially Western Europe, west coast of the US, and New England, but not as much in the other parts of the "West".

### Europe
Plot a map just for Europe. A problem here is that if I simply filter the `world` sf object, I'll get some islands away from what we usually think is Europe. Kind of feel bad for Russians since Russia is so large that it makes the map look bad and I don't have a paper from Russia in this spreadsheet. 

```{r}
pubs_on_map2(publications, zoom = "europe")
```

```{r}
pubs_per_capita(publications, "europe")
```

I didn't realize that Switzerland and Netherlands were pretty great. Again, this is a small sample size, so I take this with a grain of salt until I plot the other sheets. From the other sheets, I already know that Sweden, the UK, and Germany have many contributions. 

```{r}
pubs_on_map2(species, zoom = "europe", facet_by = "species")
```

Maybe I just made this plot for fun. Not sure what to say about it.

### USA
Also a plot just for America. I did not encounter a publication in this spreadsheet that is from Hawaii or Alaska, but I'll include Hawaii and Alaska in the map anyway in case I get one in the future.

```{r}
pubs_on_map2(publications, zoom = "usa")
```

```{r}
pubs_per_capita(publications, "usa")
```

```{r, fig.width=5, fig.height=2}
pubs_on_map2(species, zoom = "usa", facet_by = "species")
```

# Word cloud
## Titles
```{r}
plot_wordcloud(sheet)
```

## Summaries
```{r}
plot_wordcloud(sheet, col_use = "summary")
```

```{r}
plot_wordcloud(sheet, col_use = "core_principle")
```

## Tissues
```{r}
plot_wordcloud(sheet, col_use = "tissue")
```

## Over time

```{r}
range(sheet$date_published)
```

```{r}
plot_wordcloud(sheet, year_min = 2009, year_max = 2015)
```

```{r}
plot_wordcloud(sheet, year_min = 2015, year_max = 2021)
```

## Department names
```{r}
institution_words <- readRDS("output/inst_words.rds")
```

```{r}
plot_wordcloud(sheet, col_use = "department", other_stop_words = institution_words)
```

# Programming languages
```{r}
langs <- sheet %>% 
  select(year, title, language, documented:`CRAN/Bioc/pip/conda`) %>% 
  filter(!is.na(language)) %>% 
  distinct() %>% 
  mutate(language = str_split(language, "; ")) %>% 
  unnest(cols = "language")
```

```{r}
lang_img <- readRDS("output/lang_img.rds")
lang_img$image <- purrr::map(lang_img$image_paths, image_read)
```

```{r}
langs %>% 
  inner_join(lang_img, by = "language") %>% 
  pubs_per_cat(category = "language", isotype = TRUE, img_unit = 2)
```

# Data and code availability

How many publications have provided a code repo?
```{r}
ggplot(publications, aes(year, color = !is.na(repo))) +
  geom_freqpoly(binwidth = 1)
```

It seems that more recent publications are more likely to provide a repo. Is this significant? Here I fit a linear model to use year to predict proportion of publications with repo and test if the coefficients are 0.
```{r}
pub_repos <- publications %>% 
  group_by(year) %>% 
  summarize(prop_repo = sum(!is.na(repo))/length(repo))
summary(lm(prop_repo ~ year, data = pub_repos))
```

Yep, it's very significant. How about whether the code is well-documented?
```{r}
ggplot(langs, aes(year, color = documented)) +
  geom_freqpoly(binwidth = 1) +
  facet_wrap(~ language)
```

It seems that R, Python, and C++ packages are more likely to be well-documented, and MATLAB ones are less likely. Is that MATLAB culture?
```{r}
ggplot(langs, aes(year, color = `CRAN/Bioc/pip/conda`)) +
  geom_freqpoly(binwidth = 1) +
  facet_wrap(~ language)
```

It seems that most packages are not on those public repos. Why? Too lazy to write documentations?
```{r}
langs %>% 
  filter(complete.cases(.)) %>% 
  lm(data = ., documented ~ `CRAN/Bioc/pip/conda`) %>% 
  summary()
```

So it seems that packages on those public repos sort of tend to be better documented.
