---
title: "Comparisons between sheets"
author: "Lambda Moses"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{comparisons}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Here I compare different sheets and do the analysis for all sheets in the original trilogy together. Here select plots from the notebooks for the individual sheets are plotted together for easier comparison.

```{r}
library(museumst)
library(gganimate)
library(purrr)
library(dplyr)
library(tidytext)
library(tidyr)
library(ggplot2)
library(forcats)
library(scales)
library(ggrepel)
library(sf)
theme_set(theme_bw())
```

# Data
How does the trend in number of papers in the original trilogy compare to that in the prequel?

By default, the `read_metadata` function reads the appropriate sheet from a cache within this package. This may be outdated, since the Google Sheets are constantly updated. Use the argument `update = TRUE` to download the most up to date version. The default is `FALSE` to avoid API limits during automated CRAN checks.
```{r}
nms <- c("Prequel", "Microdissection", "smFISH", "Array", "ISS", "No imaging")
data_sheets <- read_metadata(nms)
```

```{r}
data_sheets <- data_sheets %>% 
  mutate(era = case_when(sheet == "Prequel" ~ "prequel",
                         TRUE ~ "current"))
```

## Number of publications over time

See the number of publications; for original trilogy sheets, each dataset has its own row so often one publication has multiple rows.
```{r}
publications <- get_pubs_df(data_sheets, "era")
```

Number of publications in each sheet
```{r}
data_sheets %>% 
  select(title, sheet) %>% 
  distinct() %>% 
  count(sheet)
```

```{r}
# For maps later in this notebook
city_gc <- geocode_inst_city(publications)
pubs_on_map2 <- partial(pubs_on_map, city_gc = city_gc)
```

By default, preprints are excluded from plots of number of publications over time, since the timing of preprints is incoherent to that of published papers. Including preprints will inflate the number of publications in recent months, and if we make the same plot a few months later, that inflation we see now will be gone and moved to a more recent date. You can add the `preprints = TRUE` argument to all functions plotting things over time in this package to include preprints. You can also use the `binwidth` argument to specify bin width in days. The default is 365 days.
```{r}
era_freqpoly(publications, era, preprints = TRUE)
```

Here we see that what's currently known as spatial transcriptomics is growing more than prequel spatial transcriptomics back in the 1990s and 2000s. Or maybe my prequel collection is incomplete, so I'm not so sure how big that peak is. What's more remarkable is the number of publications in 2020. Now it's near the end of May. We're almost half way through the year. Considering that most publications are from Western countries, for which December is the holiday season, I expect this number to double by the end of 2020.

Let me plot these lines not with the absolute year, but how many years since the first publication in the category to see how quickly these things grew. This will definitely change once I make the LCM collection more complete. Since using LCM + transcriptomics started at least as early as 2001 (the oldest paper I can find that did this is from 2001), I would expect the FALSE curve to rise earlier than the TRUE curve.
```{r}
era_freqpoly(publications, era, since_first = TRUE, preprints = TRUE)
```

So far they seem pretty parallel (which most likely won't be the case when I make the LCM collection more complete), though I certainly don't think the current era has peaked yet. Based on this, I think the current era will be much greater than the prequel era.

Here I'm making an animation on a map for prequel and original trilogy separately for number of publications per institution. These take a while to run to render all those frames, so not run for CRAN checks.

```{r, eval=FALSE}
world_prequel <- publications %>% 
  filter(era == "prequel") %>% 
  pubs_on_map(inst_gc, city_gc, per_year = TRUE)
animate(world_prequel, nframes = 200)
anim_save("output/world_prequel.gif")
```

```{r, eval=FALSE}
europe_prequel <- publications %>% 
  filter(era == "prequel") %>% 
  pubs_on_map(inst_gc, city_gc, zoom = "europe", per_year = TRUE)
animate(europe_prequel, nframes = 200)
anim_save("output/europe.gif")
```

```{r, eval=FALSE}
usa_prequel <- publications %>% 
  filter(era == "prequel") %>% 
  pubs_on_map(inst_gc, city_gc, zoom = "usa", per_year = TRUE)
animate(usa_prequel, nframes = 200)
anim_save("output/usa.gif")
```

```{r, eval=FALSE}
world_current <- publications %>% 
  filter(era == "current") %>% 
  pubs_on_map(inst_gc, city_gc, per_year = TRUE)
animate(world_current, nframes = 150)
anim_save("output/world_current.gif")
```

```{r, eval=FALSE}
europe_current <- publications %>% 
  filter(era == "current") %>% 
  pubs_on_map(inst_gc, city_gc, per_year = TRUE, zoom = "europe")
animate(europe_current, nframes = 80)
anim_save("output/europe_current.gif")
```

```{r, eval=FALSE}
usa_current <- publications %>% 
  filter(era == "current") %>% 
  pubs_on_map(inst_gc, city_gc, per_year = TRUE, zoom = "usa")
animate(usa_current)
anim_save("output/usa_current.gif")
```

## For all original trilogy or current era data
```{r}
current <- data_sheets %>% 
  filter(era == "current") %>% 
  select(date_published:journal, country:year, sheet) %>% 
  distinct()
```

```{r}
current2 <- publications %>% filter(era == "current")
```

How many per sheet? Again, I definitely don't think the LCM collection (within Microdissection) is anywhere close to complete, so microdissection is definitely the most popular one so far. LCM abstracts from PubMed search are analyzed separately.
```{r}
pubs_per_cat(current, sheet)
```

How about when broken down by the specific methods, like Visium and MERFISH?
```{r}
methods_current <- data_sheets %>% 
  select(title, date_published, method, sheet, era) %>% 
  filter(era == "current", !is.na(method)) %>% 
  distinct()
```

```{r, fig.width=6, fig.height=5}
pubs_per_cat(methods_current, method)
```

I'm not sure what to do with LCM, since I did a separate analysis on LCM literature from PubMed search. Here we see Visium has really taken off though it just got commercialized late last year.

Sheet over time. Those on RStudio Cloud: Please try different binwidths!
```{r, fig.width=5, fig.height=5}
pubs_per_year(current, "sheet", binwidth = 150, sort_by = "recent")
```

Also break this down further: this is to reproduce this plot in the other notebooks, faceted by methods.
```{r, fig.width=6, fig.height=6}
binwidths <- tribble(~ sheet, ~ binwidth,
                      "Prequel", 365,
                      "Microdissection", 365,
                      "smFISH", 365,
                      "Array", 100,
                      "ISS", 200)
pmap(binwidths, ~ data_sheets %>% 
       filter(sheet == ..1) %>% 
       unnest_cat(col_use = method) %>% 
       pubs_per_year(facet_by = "method", binwidth = ..2) +
       ggtitle(..1))
```

Also plot the most common methods
```{r, fig.width=4, fig.height=4}
methods_current %>% 
  filter(method != "LCM") %>% 
  pubs_per_year(facet_by = "method", binwidth = 150, preprints = TRUE, n_top = 4, 
                sort_by = "recent")
```

Species in all the current sheets. For prequels, it has already been plotted in the prequel notebook.
```{r}
species <- data_sheets %>%
  filter(era == "current", !is.na(species)) %>% 
  unnest_cat(species)
```

```{r}
pubs_per_cat(species, species)
```

I thought that there would be more mouse papers than human ones, but there're slightly more human ones.

Another fun isotype plot:
```{r}
pubs_per_cat(species, species, n_top = 5, isotype = TRUE, img_unit = 5)
```

```{r}
pubs_per_cat(current2, country)
```

```{r, fig.width=6, fig.height=6}
pubs_per_cat(current2, city)
```

```{r, fig.width=6, fig.height=5}
pubs_per_cat(current2, institution)
```

```{r}
pubs_per_capita(current2)
```

Unlike LCM, this is more concentrated in the West. We do have some LCM papers from countries like Egypt, India, and Turkey. Even prequel papers are more spread out.
```{r}
pubs_per_capita(current2, plot = "bar")
```

```{r}
pubs_per_capita(current, "europe")
```

```{r}
pubs_per_capita(current, "usa")
```

```{r}
pubs_per_capita(current, "usa", "bar")
```

```{r}
pubs_on_map2(current)
```

Bug: Need to distinguish between Cambridge, UK and Cambridge, MA in bar plots, though this is not a problem on maps.
```{r}
pubs_on_map2(current, zoom = "europe")
```

```{r}
pubs_on_map2(current, zoom = "usa")
```

### Text mining titles
```{r, fig.width=5, fig.height=5}
data_sheets %>% 
  filter(era == "current") %>% 
  plot_wordcloud(min.freq = 1)
```

Unlike in Prequel, "database" is not at all prominent here. Which words have the most different frequencies between prequel and current era data papers? Here I use proportion of words to normalize the different sizes of the corpus. The most extreme case is when a word is used a lot in one era and not used at all in the other.
```{r}
publications %>% 
  count(era)
```

```{r}
word_prop_scatter(publications, title, era = era)
```

Cool. It seems that the more frequent words diverge more from y = x. Here we see in the current era, there's more emphasis on single cell, transcriptomics, and the word "spatial", while in the prequel era, there was more emphasis on database, patterns, and the very notion of "gene expression". Is it that the prequel era grew in the same period when the human and mouse genomes were sequenced and culminated around the same time when the human reference genome was published; back then gene expression was considered really cool, though now this notion is so common place that we no longer make a big deal out of it? Is this why the "spatial" and "single cell" are emphasized, because it's been so hard that we make a big deal out of it when it's done? Well, I don't think many people emphasize H&E in a title, though even if it's central to a paper, because it's so easy and cheap. They would rather say "pathology" or "diagnostics" since the cool part is not H&E, but the insights of the pathologist who analyzed the images. Will there be a day when "spatial" is so common place that people no longer make a big deal out of it, and mention it just like saying "I texted my friend", which is pretty trivial now, though texting was once a big deal?

```{r, fig.width=6, fig.height=6}
data_sheets %>% 
  filter(era == "current") %>% 
  plot_wordcloud(tissue, min.freq = 1)
```

Also compare tissues in the current era to those in prequel:
```{r}
tissues <- unnest_cat(data_sheets, tissue, other_cols = "era")
```

```{r}
word_prop_scatter(tissues, tissue, era)
```

It seems that there's more Drosophila in the prequel era. But also mouse tissues other than the brain, such as the retina and genitourinary tracts (the "tract" and "system" are probably from the GUDMAP atlas). The "bulb" comes from mouse olfactory bulb, which is the go to organ to test array capture based techniques. Cell cultures also showed up here. But also note "cancer", since spatial transcriptomics in tumors is not possible with prequel era technology (except LCM, which I include in current era though the oldest LCM transcriptomics study I found is from 2001) because tumors don't have a stereotypical structure. Actually I already knew this as I was curating the papers, long before making this plot, but this plot confirms my suspicions.

For current era data papers, which programming languages (if any stated in the paper) are the most popular?
```{r}
# prequel sheet doesn't have programming language information anyway though it has that columnn
langs <- unnest_cat(data_sheets, language)
```

```{r}
pubs_per_cat(langs, language, n_top = 5, isotype = TRUE, img_unit = 5)
```

Just imagining MathWorks getting mad at me for making a pattern out of their logo. Finally, how about department names?
```{r}
word_prop_scatter(publications, department, era, other_stop_words = inst_words)
```

I already know that prequel era and current era institutions are different, and that there's more emphasis on developmental biology in the prequel era. Here "zoology" makes sense, since there're more "weird" species in the prequel era, like Ciona intestinalis. The "medical" also makes sense, since many current era datasets (more specifically, ST) are from clinical biopsies or autopsies, such as for cancer, gingivis, and ALS.

# Analysis
```{r}
nms <- c("Analysis", "Prequel analysis")
analysis_sheets <- read_metadata(nms)
```

Just to see how number of publications changed through time here
```{r}
pubs_per_year(analysis_sheets, "sheet", binwidth = 180, preprints = TRUE)
```

```{r}
era_freqpoly(analysis_sheets, sheet, preprints = TRUE)
```

```{r}
era_freqpoly(analysis_sheets, sheet, since_first = TRUE, preprints = TRUE)
```

Again, in the current era, data analysis papers grow more than in the prequel era (if my collection is complete, which I'm not sure). I don't think we have reached the peak yet.

Here, again, I'll compare word frequency between current era analysis and prequel analysis
```{r}
word_prop_scatter(analysis_sheets, era = sheet)
```

Just like for the datasets, there's more emphasis on pattern and gene expression in prequel analysis, and more emphasis on single cell and the very word "spatial" in the current era. For gene expression in prequel analysis, note that most papers from that era in this collection are about automatic classification and annotation of gene expression patterns, so it makes sense to mention "gene expression".

How about summaries of the methods?
```{r}
word_prop_scatter(analysis_sheets, summary)
```

Take this with a grain of salt since what I wrote in the summaries in part depends on my mood. Like when I was tired, I would be more concise, and when I was happy, I would be more verbose. Here we see in the current era, with single cell resolution, "cell" is more emphasized, while the BDGP atlas and ABA are not single cell resolution so the word "voxel" is used instead. 

Again, since both prequel analysis and current era analysis sheets have only about 60 titles, I think the dataset is too small for helpful modeling of how word frequencies change through time.

Finally, department names.
```{r}
word_prop_scatter(analysis_sheets, department, other_stop_words = inst_words, n_top = 15)
```

We see that a lot of the prequel analysis is from computer science departments. I wonder whether this reflects a sociological change, since biologists trained as recently as the 2000s often don't have much computational background and it seems that in the 2010s, especially after about 2015, biology has been becoming more and more computational, so more of the data analysis methods were developed within biology departments. I don't know if this trend is real of whether it's simply the timeline of my personal journy from experimental biology to computational biology. Back in the first half of 2015, I did H&E and Masson's trichrome staining. In September 2015, I changed lab, intending to learn bioinformatics, learnt R, and then started analyzing phenotype data from mouse cohorts before getting into GWAS in late 2016. So probably I only see biology becoming more and more computational because the sort of biology I've been dealing with became more and more computational. Or maybe it is real, since back in 2017, Eleazar Eskin told me about his idea of doing a master's program for postdoc biologists who want to catch up with the computational stuff, and then in 2018, the first time I TA'ed, it was the sort of intro to molecular biology class that I have taken back in my sophomore year in college (2014), and to my surprise, my section only had 2 students and the professor was dismayed that these days some "biologists" are actually mathematicians who don't even know how to do PCR. I was surprised that this class wasn't full and mandatory for biology majors, as was the case when I was a sophomore.

These are some visual explorations. Burning question: are the differences statistically significant? I think these plots are already compelling enough for now. I may need to look more into text mining literature to see what kind of tests are the best.

Also, how about plotting how number of publications about spatial data and number of publications about data analysis together?
```{r}
all_current <- rbind(current, 
                     analysis_sheets[analysis_sheets$sheet == "Analysis",
                                     names(current)])
```

```{r}
all_current <- all_current %>% 
  mutate(type = case_when(sheet == "Analysis" ~ "analysis",
                          TRUE ~ "data")) %>% 
  select(-sheet) %>% 
  distinct()
```

```{r}
era_freqpoly(all_current, type, preprints = TRUE, binwidth = 120) +
  scale_x_date(breaks = scales::breaks_pretty(10))
```

For those who viewing this vignette on RStudio Cloud, PLEASE do play around with different values of `binwidth`, since different values can give different interpretations. But I do think while before 2019, analysis did lack behind data, analysis has really taken off since 2019. However, this plot does not tell the whole story. It only says how many papers were posted online, but not the quality. Data analysis can still be behind if we don't have quality methods. But there's a fine line between "everything is so bad" and "this field is challenging" when judging that "behind". Another problem with this is that while some types of analysis methods have taken off, some other types have not. But I do think data integration and cell type inference for non-single cell resolution data have taken off. Spatially variable genes, finding characteristic gene patterns? Not really. Preprocessing? Maybe, but still not good enough for smFISH and ISS based data, though for arrayed based data, there's ST Pipeline and Space Ranger. 

How about prequel data vs. analysis?
```{r}
all_prequel <- rbind(data_sheets[data_sheets$sheet == "Prequel", names(current)],
                     analysis_sheets[analysis_sheets$sheet == "Prequel analysis", names(current)])
```

```{r}
all_prequel <- all_prequel %>% 
  mutate(type = case_when(sheet == "Prequel analysis" ~ "analysis",
                          TRUE ~ "data"))
```

```{r}
era_freqpoly(all_prequel, type, preprints = TRUE, binwidth = 365) +
  scale_x_date(breaks = scales::breaks_pretty(15))
```

So the analysis was indeed behind.

```{r}
sessionInfo()
```
